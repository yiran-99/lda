{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1845ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "#Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import pyLDAvis.sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57292442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d109c448",
   "metadata": {},
   "source": [
    "# Load 20newsgroups Dataset via Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04773cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_20newsgroups(remove =('headers', 'footers', 'quotes'))\n",
    "docs_raw = df.data\n",
    "#The ratio of training, validation and testing dataset is 80:10:10\n",
    "#Split the dataset as training dataset and testing dataset with the ratio 80%:20%\n",
    "training_data, testing_data = train_test_split(docs_raw, test_size=0.2, random_state=25)\n",
    "#Assign 10% data as validation dataset from training dataset\n",
    "validation_data, testing_data = train_test_split(testing_data, test_size=0.5, random_state=25)\n",
    "print(len(docs_raw))\n",
    "print(len(training_data))\n",
    "print(len(validation_data))\n",
    "print(len(testing_data))\n",
    "data_pre_1 = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in training_data]\n",
    "data_pre_2 = [re.sub('\\s+', ' ', sent) for sent in data_pre_1]\n",
    "data_pre_3 = [re.sub(\"\\'\", \"\", sent) for sent in data_pre_2]\n",
    "pprint(data_pre_3[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227138c0",
   "metadata": {},
   "source": [
    "# Tokenize and Further Text Clean-up (Convert to Lowercases; Remove Punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc50667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "words_data = list(sent_to_words(data_pre_3))\n",
    "print(words_data[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda17ecb",
   "metadata": {},
   "source": [
    "# Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "# Remove stopwords\n",
    "words_data_nostops = remove_stopwords(words_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd0b76",
   "metadata": {},
   "source": [
    "# Create Dictionary and Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary\n",
    "id2word = corpora.Dictionary(words_data_nostops)\n",
    "# Corpus\n",
    "texts = words_data_nostops\n",
    "# TDF-Term Document Frquency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "print(corpus[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c89860",
   "metadata": {},
   "source": [
    "# Training and Build LDA Topic Model (Gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403e23e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=2,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           eta='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a378b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_1 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=2,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           eta='symmetric',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af79a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_2 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=2,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='symmetric',\n",
    "                                           eta='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7274ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_3 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=2,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='asymmetric',\n",
    "                                           eta='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354223b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_4 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=2,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='symmetric',\n",
    "                                           eta='symmetric',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c0b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_5 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=2,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.01,\n",
    "                                           eta=0.1,\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e710f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_6 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=2,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.09,\n",
    "                                           eta=0.1,\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f3896d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda_model_7 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=2,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.01,\n",
    "                                           eta=0.9,\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594eab85",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b77586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0491f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(lda_model_1.print_topics())\n",
    "doc_lda_1 = lda_model_1[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740bc039",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(lda_model_2.print_topics())\n",
    "doc_lda_2 = lda_model_2[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b40aa37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(lda_model_3.print_topics())\n",
    "doc_lda_3 = lda_model_3[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15897168",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(lda_model_4.print_topics())\n",
    "doc_lda_4 = lda_model_4[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d7b9c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(lda_model_5.print_topics())\n",
    "doc_lda_5 = lda_model_5[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cc6ebe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint(lda_model_6.print_topics())\n",
    "doc_lda_6 = lda_model_6[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a9db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(lda_model_7.print_topics())\n",
    "doc_lda_7 = lda_model_7[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c46d7",
   "metadata": {},
   "source": [
    "# Preprocessing the Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_pre_1 = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in testing_data]\n",
    "test_data_pre_2 = [re.sub('\\s+', ' ', sent) for sent in test_data_pre_1]\n",
    "test_data_pre_3 = [re.sub(\"\\'\", \"\", sent) for sent in test_data_pre_2]\n",
    "words_test_data = list(sent_to_words(test_data_pre_3))\n",
    "words_test_data_nostops = remove_stopwords(words_test_data)\n",
    "id2word_test = corpora.Dictionary(words_test_data_nostops)\n",
    "test_texts = words_test_data_nostops\n",
    "test_corpus = [id2word_test.doc2bow(text) for text in test_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91391883",
   "metadata": {},
   "source": [
    "# Validation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004b036a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('\\nLog Perplexity: ', lda_model.log_perplexity(test_corpus)) \n",
    "#print('\\nPerplexity: ', 2**abs((lda_model.log_perplexity(test_corpus)))) \n",
    "print('\\nLog Perplexity 1: ', lda_model_1.log_perplexity(test_corpus)) \n",
    "print('\\nLog Perplexity 2: ', lda_model_2.log_perplexity(test_corpus))  \n",
    "print('\\nLog Perplexity 3: ', lda_model_3.log_perplexity(test_corpus)) \n",
    "print('\\nLog Perplexity 4: ', lda_model_4.log_perplexity(test_corpus)) \n",
    "print('\\nLog Perplexity 5: ', lda_model_5.log_perplexity(test_corpus)) \n",
    "print('\\nLog Perplexity 6: ', lda_model_6.log_perplexity(test_corpus))  \n",
    "print('\\nLog Perplexity 7: ', lda_model_7.log_perplexity(test_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fcb1fa",
   "metadata": {},
   "source": [
    "# Calculate Perplexity and Coherence Score for Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87648fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The variational bound score calculated for each word @Gensim\n",
    "print('\\nLog Perplexity: ', lda_model.log_perplexity(corpus))  \n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=words_data_nostops, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "print('\\nLog Perplexity 1: ', lda_model_1.log_perplexity(corpus)) \n",
    "coherence_model_lda_1 = CoherenceModel(model=lda_model_1, texts=words_data_nostops, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda_1 = coherence_model_lda_1.get_coherence()\n",
    "print('\\nCoherence Score 1: ', coherence_lda_1)\n",
    "\n",
    "print('\\nLog Perplexity 2: ', lda_model_2.log_perplexity(corpus)) \n",
    "coherence_model_lda_2 = CoherenceModel(model=lda_model_2, texts=words_data_nostops, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda_2 = coherence_model_lda_2.get_coherence()\n",
    "print('\\nCoherence Score 2: ', coherence_lda_2)\n",
    "\n",
    "print('\\nLog Perplexity 3: ', lda_model_3.log_perplexity(corpus)) \n",
    "coherence_model_lda_3 = CoherenceModel(model=lda_model_3, texts=words_data_nostops, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda_3 = coherence_model_lda_3.get_coherence()\n",
    "print('\\nCoherence Score 3: ', coherence_lda_3)\n",
    "\n",
    "print('\\nLog Perplexity 4: ', lda_model_4.log_perplexity(corpus)) \n",
    "coherence_model_lda_4 = CoherenceModel(model=lda_model_4, texts=words_data_nostops, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda_4 = coherence_model_lda_4.get_coherence()\n",
    "print('\\nCoherence Score 4: ', coherence_lda_4)\n",
    "\n",
    "print('\\nLog Perplexity 5: ', lda_model_5.log_perplexity(corpus)) \n",
    "coherence_model_lda_5 = CoherenceModel(model=lda_model_5, texts=words_data_nostops, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda_5 = coherence_model_lda_5.get_coherence()\n",
    "print('\\nCoherence Score 5: ', coherence_lda_5)\n",
    "\n",
    "print('\\nLog Perplexity 6: ', lda_model_6.log_perplexity(corpus)) \n",
    "coherence_model_lda_6 = CoherenceModel(model=lda_model_6, texts=words_data_nostops, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda_6 = coherence_model_lda_6.get_coherence()\n",
    "print('\\nCoherence Score 6: ', coherence_lda_6)\n",
    "\n",
    "print('\\nLog Perplexity 7: ', lda_model_7.log_perplexity(corpus)) \n",
    "coherence_model_lda_7 = CoherenceModel(model=lda_model_7, texts=words_data_nostops, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda_7 = coherence_model_lda_7.get_coherence()\n",
    "print('\\nCoherence Score 7: ', coherence_lda_7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827e3860",
   "metadata": {},
   "source": [
    "# Find the Optimal Number of Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe0df32",
   "metadata": {},
   "source": [
    "# Determine the Coherence Score for Vary Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This could be time consuming\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=5, step=5):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    log_perplexity = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics, \n",
    "                                           random_state=100,\n",
    "                                           update_every=2,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.01,\n",
    "                                           eta=0.9,\n",
    "                                           per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=words_data_nostops, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "        log_perplexity.append(model.log_perplexity(corpus))\n",
    "\n",
    "    return model_list, coherence_values, log_perplexity\n",
    "\n",
    "model_list, coherence_values, log_perplexity = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=words_data_nostops, limit=45, \n",
    "                                                        start=5, step=5)\n",
    "\n",
    "limit=45; start=5; step=5;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence Score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n",
    "\n",
    "for m, cv, p in zip(x, coherence_values, log_perplexity ):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4), \"and Likelihood Bound of\", round(p, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd081768",
   "metadata": {},
   "source": [
    "# Pick the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_final = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=2,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.01,\n",
    "                                           eta=0.9,\n",
    "                                           per_word_topics=True)\n",
    "pprint(lda_model_final.print_topics())\n",
    "doc_lda_final = lda_model_final[corpus]\n",
    "print('\\nLog Perplexity: ', lda_model_final.log_perplexity(corpus)) \n",
    "coherence_model_lda_final = CoherenceModel(model=lda_model_final, texts=words_data_nostops, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda_final = coherence_model_lda_final.get_coherence()\n",
    "print('\\nCoherence Score Final: ', coherence_lda_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06acbffe",
   "metadata": {},
   "source": [
    "# Viusalize the LDA Model Using LDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f853d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model_final, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183c8abf",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f05175",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nLog Perplexity Final on Test: ', lda_model_final.log_perplexity(test_corpus)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
